{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we might need a Relational DB for Machine Learning?\n",
    "\n",
    "There are many situations where you may need to store some stages of your data pipeline in a sql DB\n",
    "For example: Your pipeline generates a aggregate table of few million rows on which business users want to run fast queries and you want to use such tables for machine learning. Now storing data in a sql table gives you fast querying as well as auditing so its a good choice.\n",
    "\n",
    "Another situation arises when your machine learning algorithm makes certain predictions. You need to show these predictions to your customers as such this needs to be accessed by a web service. Also SQL interface is the best interface for adhoc querying. Hence storing in a sql db makes sense. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### When you can use sql db with python in your data pipeline?\n",
    "\n",
    "**Scenario 1:**\n",
    "\n",
    "Any Regression or classification problem\n",
    "\n",
    "- Data from HIVE/Hadoop job is pushed into Sql DB.\n",
    "- Your ML Algorithm needs this data so you export this as csv and use `pandas.read_csv`\n",
    "- You generate predictions as a csv and hand over the csv to dev team by storing in AWS S3 or other network file storage systems.\n",
    "- Your dev team puts the predictions in some Db for production usage.\n",
    "\n",
    "**Alternate Improved Scenario for above**\n",
    "\n",
    "- Data from HIVE/Hadoop job is pushed into Sql DB.\n",
    "- Your ML Algorithm needs this data so you connect to the DB with python and read latest data.\n",
    "- You generate predictions and put the predictions into the DB again using python.\n",
    "- Finally you automate these steps and move on.\n",
    "\n",
    "Notice how in second case: No dev team is involved and no need of network file storage. Data used is always fresh. Automation is easier since less components are involved\n",
    "\n",
    "\n",
    "**Scenario 2:**\n",
    "\n",
    "A specific time series problem \n",
    "\n",
    "\n",
    "- Sale/Price or other timeseries data is used. Like stock prices and you need to predict next _n_ weeks using past weeks data\n",
    "- Your have columns like `week`,`last_week_price`, `actual`, `predicted_price` etc. Here you will use `last_week_price` and other columns to predict the `predicted_price` in the start of the week.\n",
    "- After the week is over you will fill the `actual` column and calculate error. Report the error for the week and other stats over last few weeks.\n",
    "\n",
    "\n",
    "In this scenario if you use file based storage then every week you will read/retrieve entire file. And then overwrite the whole file. But in case you use a SQL storage you will only insert/update few rows for the weeks you are predicting.\n",
    "\n",
    "**Scenario 3:**\n",
    "\n",
    "Running Testing of multiple Models over a period of time. Here as well you can either use a file based system where you have a file per model and each day/week/month you keep overwriting the files. Or you can use a sql database and have a table with an extra column `model_used` and just keep adding to table. After sometime a single query can be fired and stats can be collected from the table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to connect and do SQL with Python? \n",
    "\n",
    "Just like in java world we a have 2 options\n",
    "- Use an ORM (Object Relational Mapper) like SQLAlchemy. \n",
    "    - This option is good if you intend to build a microservice, store domain entities, and serve customers. Like storing customer info, address, purchases, cart contents etc. Here you want to have classes which Object Oriented programming and these are stored in Databases\n",
    "- Use direct SQL Connectors and write some lightweight wrappers on top for convinience.\n",
    "    - This option is good for data-science use cases where our data is mostly denormalized and most use cases involve ad-hoc queries. We use a Database to have incremental updates to our data and auditing.\n",
    "\n",
    "In this tutorial we will learn to use MySQL with Python and create a simple wrapper that we can use. We will use the MySQL official python package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the package and Table Setup\n",
    "\n",
    "`pip install mysql-connector-python`\n",
    "\n",
    "I assume you have access to a MySQL installed Machine. In case you don't try with AWS RDS/ AWS Aurora. You can also install mysql on your personal system and try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T09:54:14.943313Z",
     "start_time": "2018-06-13T09:54:14.178856Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mysql.connector import MySQLConnection, Error\n",
    "from datetime import date, datetime, timedelta\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "conn_details = {\"host\":\"localhost\",\"database\":\"\",\"user\":\"root\",\"password\":\"\"}\n",
    "\n",
    "conn = MySQLConnection(**conn_details)\n",
    "if not conn.is_connected():\n",
    "    raise AssertionError(\"Could not connect to DB\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T10:09:05.931949Z",
     "start_time": "2018-06-13T10:09:05.655818Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_db_command = \"CREATE DATABASE scholar;\"\n",
    "\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(create_db_command)\n",
    "finally:\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice How we enclosed the query running in a try-finally block. This ensures that we close the cursor even if an exception is thrown. In reality the `conn` variable (opening a connection should be in try-finally as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the database we just created and creating a table for this tutorial\n",
    "\n",
    "We will create a table for storing students marks in exams. Columns will be \n",
    "- student_id(int), \n",
    "- date_given(Date), \n",
    "- exam_id(int), \n",
    "- total(int), \n",
    "- score(int), \n",
    "- passed(Boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T10:10:46.373243Z",
     "start_time": "2018-06-13T10:10:46.345872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_db_command = \"use scholar;\"\n",
    "\n",
    "create_table_command = \"\"\"\n",
    "CREATE TABLE `exam_marks` (\n",
    "  `student` bigint(11) unsigned NOT NULL,\n",
    "  `date_given` date NOT NULL,\n",
    "  `exam_id` int(11) NOT NULL,\n",
    "  `total` int(11) NOT NULL,\n",
    "  `score` int(11) DEFAULT NULL,\n",
    "  `passed` CHAR(1) DEFAULT NULL,\n",
    "  PRIMARY KEY (`student`,`exam_id`,`date_given`)\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(use_db_command)\n",
    "    cursor.execute(create_table_command)\n",
    "finally:\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting and Updating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Utility Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T14:36:00.146438Z",
     "start_time": "2018-06-13T14:36:00.054210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch winning probability 0.6716\n",
      "No Switch winning probability 0.3284\n"
     ]
    }
   ],
   "source": [
    "ctr_switch = 0\n",
    "ctr_no_switch = 0\n",
    "total = 10000\n",
    "for i in range(total):\n",
    "    rn = np.random.randint(1,4)\n",
    "    guess = np.random.randint(1,4)\n",
    "    removable = next(iter(set([1,2,3]) - set([guess,rn])))\n",
    "    remaining = set([1,2,3])-set([removable])\n",
    "    # we switch\n",
    "    g2 = next(iter(remaining - set([guess])))\n",
    "    if g2==rn:\n",
    "        ctr_switch=ctr_switch+1\n",
    "    if guess==rn:\n",
    "        ctr_no_switch=ctr_no_switch+1\n",
    "        \n",
    "print(\"Switch winning probability %s\"%(ctr_switch/total))\n",
    "print(\"No Switch winning probability %s\"%(ctr_no_switch/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
