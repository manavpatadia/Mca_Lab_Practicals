{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "40ea3ee4-1984-4b62-80e1-0fd7a66ab585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c21c9d69-3bae-4c40-bf28-9d45d578dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lm = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "pm = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "366a29e8-1834-458b-8c03-3ec1cce1ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_input_df = pd.read_csv(\"final_input_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "579e9893-407b-4dfa-b1bb-804aa86c5b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15264</th>\n",
       "      <td>art raptorx joschuaknuppe image rex island scute</td>\n",
       "      <td>MonsterVerse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27836</th>\n",
       "      <td>fav godzilla</td>\n",
       "      <td>MonsterVerse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35958</th>\n",
       "      <td>creamycumshotz batman riddler</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51126</th>\n",
       "      <td>johnxuandou wow series potter queer inclusivit...</td>\n",
       "      <td>Wizarding World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14670</th>\n",
       "      <td>shitfuckers war gansters</td>\n",
       "      <td>Star Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31348</th>\n",
       "      <td>mcu marvel fan fun drama</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28404</th>\n",
       "      <td>hack stay camera woman georgia mcdonalds film ...</td>\n",
       "      <td>Star Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>part memesmonday heard darth jar jar iron star...</td>\n",
       "      <td>Star Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25655</th>\n",
       "      <td>number people wandavision hawkeye anyone moon ...</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20086</th>\n",
       "      <td>spring bob flambeur rififi persuasion man harp...</td>\n",
       "      <td>MonsterVerse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  \\\n",
       "15264   art raptorx joschuaknuppe image rex island scute   \n",
       "27836                                       fav godzilla   \n",
       "35958                      creamycumshotz batman riddler   \n",
       "51126  johnxuandou wow series potter queer inclusivit...   \n",
       "14670                           shitfuckers war gansters   \n",
       "...                                                  ...   \n",
       "31348                           mcu marvel fan fun drama   \n",
       "28404  hack stay camera woman georgia mcdonalds film ...   \n",
       "4636   part memesmonday heard darth jar jar iron star...   \n",
       "25655  number people wandavision hawkeye anyone moon ...   \n",
       "20086  spring bob flambeur rififi persuasion man harp...   \n",
       "\n",
       "                           label  \n",
       "15264               MonsterVerse  \n",
       "27836               MonsterVerse  \n",
       "35958       DC Extended Universe  \n",
       "51126            Wizarding World  \n",
       "14670                  Star Wars  \n",
       "...                          ...  \n",
       "31348  Marvel Cinematic Universe  \n",
       "28404                  Star Wars  \n",
       "4636                   Star Wars  \n",
       "25655  Marvel Cinematic Universe  \n",
       "20086               MonsterVerse  \n",
       "\n",
       "[36023 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f0003bd-e864-4f6e-97dc-245ce188da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('r8-train-all-terms.txt', header=None, sep='\\t')\n",
    "#test = pd.read_csv('r8-test-all-terms.txt', header=None, sep='\\t')\n",
    "#train.columns = ['label', 'content']\n",
    "#test.columns = ['label', 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c0a01ea-2fed-4b04-96cc-ada2aaf394e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(token_list): ## to remove tokens like zzzzz, aa, kkk, one/two letter toekns, aaaanndd, aab\n",
    "    new_tkn_lst = []\n",
    "    for tkn in token_list:\n",
    "        if((len(tkn) >= 3 or tkn == \"dc\") and len(set(list(tkn))) > 1 and len(re.findall(r'((\\w)\\2{2,})', tkn)) == 0  and len(re.findall(r'(^(\\w)\\2{1,})', tkn)) == 0):\n",
    "            new_tkn_lst.append(tkn)\n",
    "    return new_tkn_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7ad12376-40d3-408e-a18b-9ece46319ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_doc(txt, stem, lemma, stop_wrds, selected_tags):\n",
    "    try:\n",
    "        txt = txt.lower()\n",
    "        txt = re.sub(r'http\\S+', '', txt) #remove URLs\n",
    "        txt = re.sub('[^a-zA-Z-]', ' ', txt ) #removing punctuations numbers\n",
    "        wrd_tkn = word_tokenize(txt)\n",
    "        wrd_tkn = clean_tokens(wrd_tkn)\n",
    "        final_wrd_tkn = wrd_tkn\n",
    "        if(stop_wrds):\n",
    "            final_wrd_tkn = [word for word in final_wrd_tkn if not word in set(stopwords.words('english')) ]\n",
    "        if(stem):\n",
    "            final_wrd_tkn = [pm.stem(word) for word in final_wrd_tkn]\n",
    "        if(lemma):\n",
    "            final_wrd_tkn = [lm.lemmatize(word) for word in final_wrd_tkn]\n",
    "        if(len(selected_tags) > 0):\n",
    "            final_wrd_tkn = pos_tag(final_wrd_tkn)\n",
    "            final_wrd_tkn = [word[0] for word in final_wrd_tkn if word[1] in selected_tags ]\n",
    "        return final_wrd_tkn\n",
    "    except Exception as e:\n",
    "        print(txt)\n",
    "        print(\"Exception Caught: \", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9c70f1b7-ba9b-459b-8704-4749736a5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stems_lemma(tags, final_input_df, fresh_load):\n",
    "    if(not fresh_load):\n",
    "        final_input_df = pd.read_csv(\"final_input_cleaned_stem_lemma.csv\")\n",
    "        print(\"Stems and Lemma extracted to final_input_cleaned_stem_lemma.csv\")\n",
    "    else:\n",
    "        stem_cleaned_tokens = []\n",
    "        lemma_cleaned_tokens = []\n",
    "        for i in tqdm(final_input_df.index):\n",
    "            stem_cleaned_tokens.append(preprocess_doc(txt = final_input_df['full_text'][i], stem = True, lemma = False, stop_wrds = True, selected_tags = tags))\n",
    "        final_input_df['stem_cleaned_tokens'] = stem_cleaned_tokens\n",
    "        for i in tqdm(final_input_df.index):\n",
    "            lemma_cleaned_tokens.append(preprocess_doc(txt = final_input_df['full_text'][i], stem = False, lemma = True, stop_wrds = True, selected_tags = tags))\n",
    "        final_input_df['lemma_cleaned_tokens'] = lemma_cleaned_tokens\n",
    "        final_input_df.to_csv(\"final_input_cleaned_stem_lemma.csv\", index = False)\n",
    "        print(\"Stems and Lemma extracted to final_input_cleaned_stem_lemma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0f808cf-d711-4635-acaf-7f3f2dcacc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51462/51462 [06:52<00:00, 124.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51462/51462 [06:43<00:00, 127.51it/s]\n"
     ]
    }
   ],
   "source": [
    "selected_tags = ['NN','NNP','NNPS','NNS']\n",
    "extract_stems_lemma(selected_tags, final_input_df, fresh_load = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "16413e71-b380-4814-91fe-506aad726396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "      <th>stem_cleaned_tokens</th>\n",
       "      <th>lemma_cleaned_tokens</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‘#GuardiansoftheGalaxy 3’ Star #KarenGillan Sa...</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>['guardiansofthegalaxi', 'star', 'karengillan'...</td>\n",
       "      <td>['guardiansofthegalaxy', 'star', 'karengillan'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My friend recommend me a few shows and I have ...</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "      <td>['friend', 'show', 'idea', 'flash', 'guy', 'sh...</td>\n",
       "      <td>['friend', 'show', 'idea', 'flash', 'guy', 'sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Papa__Drago Godzilla would win easily but jus...</td>\n",
       "      <td>MonsterVerse</td>\n",
       "      <td>['papa', 'drago', 'godzilla', 'hundr', 'titan'...</td>\n",
       "      <td>['papa', 'drago', 'godzilla', 'titan', 'omg']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batman &amp;amp; Robin...It's so camp https://t.co...</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "      <td>['batman', 'robin', 'camp']</td>\n",
       "      <td>['batman', 'robin', 'camp']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why is huge ant man moving so slow</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>['ant', 'man', 'move']</td>\n",
       "      <td>['ant', 'man']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51457</th>\n",
       "      <td>@tortoisethatwon @aightmoe @Sarcasm_bender End...</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "      <td>['tortoisethatwon', 'aightmo', 'sarcasm', 'ben...</td>\n",
       "      <td>['tortoisethatwon', 'aightmoe', 'sarcasm', 'be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51458</th>\n",
       "      <td>@iHrtProngs SIRIUS BLACK DOES NOT HAVE A BAD H...</td>\n",
       "      <td>Wizarding World</td>\n",
       "      <td>['hair', 'day']</td>\n",
       "      <td>['ihrtprongs', 'hair', 'day']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51459</th>\n",
       "      <td>@aNorthernGarden @fiona_skywalker Agreed. She ...</td>\n",
       "      <td>Star Wars</td>\n",
       "      <td>['fiona', 'skywalk', 'liter', 'ask', 'comment'...</td>\n",
       "      <td>['fiona', 'skywalker', 'input', 'earns', 'hous...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51460</th>\n",
       "      <td>And so my long Marvel-watching journey comes t...</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>['marvel-watch', 'journey', 'caught', 'endless...</td>\n",
       "      <td>['journey', 'end', 'franchise', 'eon', 'rest',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51461</th>\n",
       "      <td>@mumbichilopa_jr Contact @DzaddyX  for more in...</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>['mumbichilopa', 'contact', 'dzaddyx', 'inform']</td>\n",
       "      <td>['mumbichilopa', 'contact', 'dzaddyx', 'inform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51462 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  \\\n",
       "0      ‘#GuardiansoftheGalaxy 3’ Star #KarenGillan Sa...   \n",
       "1      My friend recommend me a few shows and I have ...   \n",
       "2      @Papa__Drago Godzilla would win easily but jus...   \n",
       "3      Batman &amp; Robin...It's so camp https://t.co...   \n",
       "4                     why is huge ant man moving so slow   \n",
       "...                                                  ...   \n",
       "51457  @tortoisethatwon @aightmoe @Sarcasm_bender End...   \n",
       "51458  @iHrtProngs SIRIUS BLACK DOES NOT HAVE A BAD H...   \n",
       "51459  @aNorthernGarden @fiona_skywalker Agreed. She ...   \n",
       "51460  And so my long Marvel-watching journey comes t...   \n",
       "51461  @mumbichilopa_jr Contact @DzaddyX  for more in...   \n",
       "\n",
       "                           label  \\\n",
       "0      Marvel Cinematic Universe   \n",
       "1           DC Extended Universe   \n",
       "2                   MonsterVerse   \n",
       "3           DC Extended Universe   \n",
       "4      Marvel Cinematic Universe   \n",
       "...                          ...   \n",
       "51457       DC Extended Universe   \n",
       "51458            Wizarding World   \n",
       "51459                  Star Wars   \n",
       "51460  Marvel Cinematic Universe   \n",
       "51461  Marvel Cinematic Universe   \n",
       "\n",
       "                                     stem_cleaned_tokens  \\\n",
       "0      ['guardiansofthegalaxi', 'star', 'karengillan'...   \n",
       "1      ['friend', 'show', 'idea', 'flash', 'guy', 'sh...   \n",
       "2      ['papa', 'drago', 'godzilla', 'hundr', 'titan'...   \n",
       "3                            ['batman', 'robin', 'camp']   \n",
       "4                                 ['ant', 'man', 'move']   \n",
       "...                                                  ...   \n",
       "51457  ['tortoisethatwon', 'aightmo', 'sarcasm', 'ben...   \n",
       "51458                                    ['hair', 'day']   \n",
       "51459  ['fiona', 'skywalk', 'liter', 'ask', 'comment'...   \n",
       "51460  ['marvel-watch', 'journey', 'caught', 'endless...   \n",
       "51461   ['mumbichilopa', 'contact', 'dzaddyx', 'inform']   \n",
       "\n",
       "                                    lemma_cleaned_tokens  label_id  \n",
       "0      ['guardiansofthegalaxy', 'star', 'karengillan'...         1  \n",
       "1      ['friend', 'show', 'idea', 'flash', 'guy', 'sh...         0  \n",
       "2          ['papa', 'drago', 'godzilla', 'titan', 'omg']         2  \n",
       "3                            ['batman', 'robin', 'camp']         0  \n",
       "4                                         ['ant', 'man']         1  \n",
       "...                                                  ...       ...  \n",
       "51457  ['tortoisethatwon', 'aightmoe', 'sarcasm', 'be...         0  \n",
       "51458                      ['ihrtprongs', 'hair', 'day']         4  \n",
       "51459  ['fiona', 'skywalker', 'input', 'earns', 'hous...         3  \n",
       "51460  ['journey', 'end', 'franchise', 'eon', 'rest',...         1  \n",
       "51461  ['mumbichilopa', 'contact', 'dzaddyx', 'inform...         1  \n",
       "\n",
       "[51462 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_input_df = pd.read_csv(\"final_input_cleaned_stem_lemma.csv\")\n",
    "final_input_df['label_id'] = final_input_df['label'].astype(\"category\").cat.codes\n",
    "final_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "294049bc-f137-4001-a9cd-9fa519f80e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem_cleaned_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['guardiansofthegalaxi', 'star', 'karengillan'...</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['friend', 'show', 'idea', 'flash', 'guy', 'sh...</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['papa', 'drago', 'godzilla', 'hundr', 'titan'...</td>\n",
       "      <td>MonsterVerse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['batman', 'robin', 'camp']</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ant', 'man', 'move']</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 stem_cleaned_tokens  \\\n",
       "0  ['guardiansofthegalaxi', 'star', 'karengillan'...   \n",
       "1  ['friend', 'show', 'idea', 'flash', 'guy', 'sh...   \n",
       "2  ['papa', 'drago', 'godzilla', 'hundr', 'titan'...   \n",
       "3                        ['batman', 'robin', 'camp']   \n",
       "4                             ['ant', 'man', 'move']   \n",
       "\n",
       "                       label  label_id  \n",
       "0  Marvel Cinematic Universe         1  \n",
       "1       DC Extended Universe         0  \n",
       "2               MonsterVerse         2  \n",
       "3       DC Extended Universe         0  \n",
       "4  Marvel Cinematic Universe         1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorization = final_input_df[['stem_cleaned_tokens', 'label', 'label_id']]\n",
    "df_vectorization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "558ebd54-8581-47d6-98f3-30711757a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'DC Extended Universe', 1: 'Marvel Cinematic Universe', 2: 'MonsterVerse', 3: 'Star Wars', 4: 'Wizarding World'}\n"
     ]
    }
   ],
   "source": [
    "dfvg = df_vectorization.groupby(['label', 'label_id'])\n",
    "classes = {}\n",
    "for d in dfvg:\n",
    "    classes[d[0][1]] = d[0][0]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d842f7eb-129f-4a95-912d-923efc3b4acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_cleaned_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['guardiansofthegalaxy', 'star', 'karengillan'...</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['friend', 'show', 'idea', 'flash', 'guy', 'sh...</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['papa', 'drago', 'godzilla', 'titan', 'omg']</td>\n",
       "      <td>MonsterVerse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['batman', 'robin', 'camp']</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ant', 'man']</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                lemma_cleaned_tokens  \\\n",
       "0  ['guardiansofthegalaxy', 'star', 'karengillan'...   \n",
       "1  ['friend', 'show', 'idea', 'flash', 'guy', 'sh...   \n",
       "2      ['papa', 'drago', 'godzilla', 'titan', 'omg']   \n",
       "3                        ['batman', 'robin', 'camp']   \n",
       "4                                     ['ant', 'man']   \n",
       "\n",
       "                       label  label_id  \n",
       "0  Marvel Cinematic Universe         1  \n",
       "1       DC Extended Universe         0  \n",
       "2               MonsterVerse         2  \n",
       "3       DC Extended Universe         0  \n",
       "4  Marvel Cinematic Universe         1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding = final_input_df[['lemma_cleaned_tokens', 'label', 'label_id']]\n",
    "df_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66f188d5-0592-47c3-bb5c-92d3d20679d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51462"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4495f20d-393d-4b11-8c86-1e832c6302f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_stemmed_data = []\n",
    "list_embedding_data = []\n",
    "for i in df_vectorization.index:\n",
    "    exec(\"lst = \" + df_vectorization['stem_cleaned_tokens'][i])\n",
    "    lst = clean_tokens(lst)\n",
    "    list_stemmed_data.append(\" \".join(lst))\n",
    "    exec(\"lst2 = \" + df_embedding['lemma_cleaned_tokens'][i])\n",
    "    lst2 = clean_tokens(lst2)\n",
    "    list_embedding_data.append(\" \".join(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ac1a1516-7525-45e8-be52-b3511e7ee94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.Series(list_embedding_data)\n",
    "y = df_embedding['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True, stratify = y, random_state = 3)\n",
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "test = pd.concat([X_test, y_test], axis = 1)\n",
    "train.columns = ['full_text', 'label']\n",
    "test.columns = ['full_text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "74268c91-168c-4ffc-b178-12dbbd72a758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15264</th>\n",
       "      <td>art raptorx joschuaknuppe image rex island scute</td>\n",
       "      <td>MonsterVerse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27836</th>\n",
       "      <td>fav godzilla</td>\n",
       "      <td>MonsterVerse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35958</th>\n",
       "      <td>creamycumshotz batman riddler</td>\n",
       "      <td>DC Extended Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51126</th>\n",
       "      <td>johnxuandou wow series potter queer inclusivit...</td>\n",
       "      <td>Wizarding World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14670</th>\n",
       "      <td>shitfuckers war gansters</td>\n",
       "      <td>Star Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31348</th>\n",
       "      <td>mcu marvel fan fun drama</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28404</th>\n",
       "      <td>hack stay camera woman georgia mcdonalds film ...</td>\n",
       "      <td>Star Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>part memesmonday heard darth jar jar iron star...</td>\n",
       "      <td>Star Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25655</th>\n",
       "      <td>number people wandavision hawkeye anyone moon ...</td>\n",
       "      <td>Marvel Cinematic Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20086</th>\n",
       "      <td>spring bob flambeur rififi persuasion man harp...</td>\n",
       "      <td>MonsterVerse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  \\\n",
       "15264   art raptorx joschuaknuppe image rex island scute   \n",
       "27836                                       fav godzilla   \n",
       "35958                      creamycumshotz batman riddler   \n",
       "51126  johnxuandou wow series potter queer inclusivit...   \n",
       "14670                           shitfuckers war gansters   \n",
       "...                                                  ...   \n",
       "31348                           mcu marvel fan fun drama   \n",
       "28404  hack stay camera woman georgia mcdonalds film ...   \n",
       "4636   part memesmonday heard darth jar jar iron star...   \n",
       "25655  number people wandavision hawkeye anyone moon ...   \n",
       "20086  spring bob flambeur rififi persuasion man harp...   \n",
       "\n",
       "                           label  \n",
       "15264               MonsterVerse  \n",
       "27836               MonsterVerse  \n",
       "35958       DC Extended Universe  \n",
       "51126            Wizarding World  \n",
       "14670                  Star Wars  \n",
       "...                          ...  \n",
       "31348  Marvel Cinematic Universe  \n",
       "28404                  Star Wars  \n",
       "4636                   Star Wars  \n",
       "25655  Marvel Cinematic Universe  \n",
       "20086               MonsterVerse  \n",
       "\n",
       "[36023 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "56940f53-e07f-43b9-a4d6-0b8833b9527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "    def __init__(self):\n",
    "        # load in pre-trained word vectors\n",
    "        print('Loading word vectors...')\n",
    "        word2vec = {}\n",
    "        embedding = []\n",
    "        idx2word = []\n",
    "        with open('G:\\spark_big_files\\glove.6B\\glove.6B.50d.txt', encoding=\"utf-8\") as f:\n",
    "            # is just a space-separated text file in the format:\n",
    "            # word vec[0] vec[1] vec[2] ...\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vec = np.asarray(values[1:], dtype='float32')\n",
    "                word2vec[word] = vec\n",
    "                embedding.append(vec)\n",
    "                idx2word.append(word)\n",
    "        print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "        # save for later\n",
    "        self.word2vec = word2vec\n",
    "        self.embedding = np.array(embedding)\n",
    "        self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "        self.V, self.D = self.embedding.shape\n",
    "\n",
    "    def fit(self, data):\n",
    "        pass\n",
    "\n",
    "    def transform(self, data):\n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = sentence.lower().split()\n",
    "            vecs = []\n",
    "            for word in tokens:\n",
    "                if word in self.word2vec:\n",
    "                    vec = self.word2vec[word]\n",
    "                    vecs.append(vec)\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40ad4a05-fcbf-44b1-afc1-a5eb4477dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecVectorizer:\n",
    "    def __init__(self):\n",
    "        print(\"Loading in word vectors...\")\n",
    "        self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "            'G:\\spark_big_files\\GoogleNews-vectors-negative300.bin\\GoogleNews-vectors-negative300.bin', encoding=\"utf-8\",\n",
    "            binary=True\n",
    "        )\n",
    "        print(\"Finished loading in word vectors\")\n",
    "\n",
    "    def fit(self, data):\n",
    "        pass\n",
    "\n",
    "    def transform(self, data):\n",
    "        # determine the dimensionality of vectors\n",
    "        v = self.word_vectors.get_vector('king')\n",
    "        self.D = v.shape[0]\n",
    "\n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = sentence.split()\n",
    "            vecs = []\n",
    "            m = 0\n",
    "            for word in tokens:\n",
    "                try:\n",
    "                    # throws KeyError if word not found\n",
    "                    vec = self.word_vectors.get_vector(word)\n",
    "                    vecs.append(vec)\n",
    "                    m += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f94d359-ec09-46a4-9c6b-04a3b215952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Numer of samples with no words found: 302 / 36023\n",
      "Numer of samples with no words found: 123 / 15439\n"
     ]
    }
   ],
   "source": [
    "vectorizer = GloveVectorizer()\n",
    "# vectorizer = Word2VecVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(train.full_text)\n",
    "Ytrain = train.label\n",
    "\n",
    "Xtest = vectorizer.transform(test.full_text)\n",
    "Ytest = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "70b11772-f9a8-4471-821f-d5d32d28af48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9857590983538295\n",
      "test score: 0.7575620182654317\n",
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the model, train it, print scores\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fa1d89e4-4e4d-4a25-939c-c2fcd8e5a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 627 / 36023\n",
      "Numer of samples with no words found: 287 / 15439\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer_wv = Word2VecVectorizer()\n",
    "# vectorizer = Word2VecVectorizer()\n",
    "Xtrain_wv = vectorizer_wv.fit_transform(train.full_text)\n",
    "Ytrain_wv = train.label\n",
    "\n",
    "Xtest_wv = vectorizer_wv.transform(test.full_text)\n",
    "Ytest_wv = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee83210b-f0de-4fb3-91f9-4aa3560479eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9752935624462149\n",
      "test score: 0.7699980568689682\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the model, train it, print scores\n",
    "model_wv = RandomForestClassifier(n_estimators=200)\n",
    "model_wv.fit(Xtrain_wv, Ytrain_wv)\n",
    "print(\"train score:\", model_wv.score(Xtrain_wv, Ytrain_wv))\n",
    "print(\"test score:\", model_wv.score(Xtest_wv, Ytest_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "806d8499-a53b-4f91-8dfb-d8ee56eb90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_f = sorted(glob.glob(\"df_rottentomatoes_reviews_predicted*\"), key=os.path.getmtime)\n",
    "output_file_name = list_f[0]\n",
    "df_rottentomatoes_reviews = pd.read_csv(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "16216b3e-fd53-4bed-a425-7f126713ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_valid_emb = []\n",
    "classes = {0: 'DC Extended Universe', 1: 'Marvel Cinematic Universe', 2: 'MonsterVerse', 3: 'Star Wars', 4: 'Wizarding World'}\n",
    "for i in df_rottentomatoes_reviews.index:\n",
    "    validation_text = df_rottentomatoes_reviews[\"review\"][i]\n",
    "    validation_text = preprocess_doc(validation_text, stem = False, lemma = True, stop_wrds = True, selected_tags = selected_tags)\n",
    "    X_valid_emb.append(validation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ce344d6-fb46-43e0-9c7c-d47789f44b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_emb = [\" \".join(l) for l in X_valid_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1963b91e-9e55-40d8-b0f1-39c3342b6ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['godzilla monster thing people love see child godzilla improvement term sheer entertainment movie cgi action story fun dialogue fun set-pieces budget make godzilla fan movie movie movie godzilla character movie lizard intelligence rodan mothra ghidorah head personality thing godzilla film fun fan showa heisei godzilla movie',\n",
       " 'movie horror maestro comedy script way movie opinion fan boy']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_emb[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ee297a21-58db-49de-b41c-0107073cdddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 265\n"
     ]
    }
   ],
   "source": [
    "X_valid = pd.Series(X_valid_emb)\n",
    "Xtest_wv = vectorizer_wv.transform(X_valid)\n",
    "Ytest_wv = df_rottentomatoes_reviews['label_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4ff87073-4368-43ea-b5a1-a2655c82e18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 265\n"
     ]
    }
   ],
   "source": [
    "Xtest_gv = vectorizer.transform(X_valid)\n",
    "Ytest_gv = df_rottentomatoes_reviews['label_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a88eeb3d-0d4a-4902-896b-2f343efe9661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word vector test score: 0.7471698113207547\n",
      "Glove Vectorizer test score: 0.6490566037735849\n"
     ]
    }
   ],
   "source": [
    "print(\"word vector test score:\", model_wv.score(Xtest_wv, Ytest_wv))\n",
    "print(\"Glove Vectorizer test score:\", model.score(Xtest_gv, Ytest_gv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa9900-95ef-4f28-a4c8-2247e720e82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
